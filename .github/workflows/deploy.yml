name: Deploy API

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  DOCKER_IMAGE: alinacharon/stackoverflow-predictor
  DOCKER_TAG: ${{ github.sha }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Git LFS
        run: |
          sudo apt-get update
          sudo apt-get install git-lfs
          git lfs install
          git lfs version
          git lfs ls-files

      - name: Pull Git LFS files
        run: |
          echo "Pulling Git LFS files..."
          git lfs pull
          echo "Git LFS files pulled. Listing files:"
          git lfs ls-files
          echo "Checking file sizes:"
          ls -lh models/

      - name: Verify model files
        run: |
          echo "Checking model files..."
          ls -la models/
          if [ ! -f "models/model.pkl" ] || [ ! -f "models/mlb.pkl" ]; then
            echo "Error: Model files are missing!"
            exit 1
          fi
          echo "Model files found successfully"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov
          pip install tensorflow==2.11.0 tensorflow-hub==0.12.0 tensorflow-text==2.11.0
          pip install scikit-learn==1.0.2 xgboost==1.7.6
          python -c "import tensorflow as tf; print(f'TensorFlow version: {tf.__version__}')"
          python -c "import tensorflow_hub as hub; print(f'TensorFlow Hub version: {hub.__version__}')"
          python -c "import sklearn; print(f'scikit-learn version: {sklearn.__version__}')"
          python -c "import xgboost; print(f'XGBoost version: {xgboost.__version__}')"

      - name: Download NLTK data
        run: |
          python -c "import nltk; \
            nltk.download('punkt'); \
            nltk.download('averaged_perceptron_tagger'); \
            nltk.download('wordnet'); \
            nltk.download('stopwords'); \
            nltk.download('averaged_perceptron_tagger_eng')"

      - name: Run tests
        run: |
          pytest tests/ -v --cov=api

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }},${{ env.DOCKER_IMAGE }}:latest
          cache-from: type=registry,ref=${{ env.DOCKER_IMAGE }}:buildcache
          cache-to: type=registry,ref=${{ env.DOCKER_IMAGE }}:buildcache,mode=max

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to EC2
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ubuntu
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            docker pull ${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}

            docker stop stackoverflow-predictor || true
            docker rm stackoverflow-predictor || true

            docker run -d \
              --name stackoverflow-predictor \
              --restart unless-stopped \
              -p 3000:3000 \
              -v /app/logs:/app/logs \
              ${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}

            docker image prune -f
